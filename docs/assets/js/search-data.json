{"0": {
    "doc": "Choices",
    "title": "Choices",
    "content": " ",
    "url": "/choices/",
    "relUrl": "/choices/"
  },"1": {
    "doc": "Dylan",
    "title": "Dylan’s Reflections",
    "content": " ",
    "url": "/reflections/dylan/#dylans-reflections",
    "relUrl": "/reflections/dylan/#dylans-reflections"
  },"2": {
    "doc": "Dylan",
    "title": "Dylan",
    "content": " ",
    "url": "/reflections/dylan/",
    "relUrl": "/reflections/dylan/"
  },"3": {
    "doc": "Introduction",
    "title": "Introduction and Justification",
    "content": "Safety dominates the self-driving car narrative, representing the area of both greatest benefit and greatest concern (Kim, Park, Oh, Lee, &amp; Chung, 2019). Proponents of the technology expound the virtues of the autonomous vehicle (AV). The key talking points are compelling: an ever-vigilante machine that reacts at the speed of thought makes humans seem like apes behind the wheel. For detractors, safety is the area of greatest concern. Deep learning models are fast, but they are brittle in novel situations, and we understand their decision-making processes even less than we understand our own. Recent advances in neural network mapping may give more insight into AI decision-making in future, but this is still far removed from the level of control we are accustomed to having over safety-critical automated systems. Since the public unveiling of the Google Self-driving Car project in 2010, now Waymo, investment has been thick and fast. Now, after over a decade of delays and setbacks self-driving technology is no longer on the horizon, the push for integration is happening now. In August 2022 the British government unveiled their plan for a wider rollout of self-driving vehicles by 2025, backed by a £100 million investment “to support industry investment and fund research on safety developments.” . New Zealand currently has such no roadmap, despite having both high car ownership and high car dependency. In the absence of government programs, usual factors such as physical isolation and a small market meant AV manufacturers had no incentive to even consider the country as a candidate testbed. However, the MOT issued a report in 2022 outlining possible impacts and as well as paths forward, and the NZTA is open to working with manufacturers interested in testing their vehicles in New Zealand. ",
    "url": "/#introduction-and-justification",
    "relUrl": "/#introduction-and-justification"
  },"4": {
    "doc": "Introduction",
    "title": "SAE five levels of automation",
    "content": "The Society of Automated Vehicles International has defines five levels of automation, with a sixth level, zero, for unautomated vehicles. Levels 0-2 is categorised by features that support the driver, such as adaptive cruise control and lane departure warning. Even if the vehicle is controlling the acceleration, breaking, or steering of the vehicle, this classification considers that the human driver is still driving the vehicle. The classification considers the remaining three levels to be automated, and that a human in the driver’s seat is not driving whilst these features are active. At Level 3, the vehicle can drive itself, but the human driver must take over when prompted to. Whilst SAE international characterises this as a peer of more automated Levels 4 and 5, colloquially vehicles with these features are rarely considered to be ‘the self-driving car.’ . At Levels 4 and 5, vehicles can complete a trip without any driver input and are typically considered to be ‘self-driving’. Fifth level vehicles can drive themselves regardless of limitations that may be imposed on Fourth Level vehicles such as geo-fencing, poor visibility etc. Fifth level may be considered the ultimate goal of self-driving vehicle development. ",
    "url": "/#sae-five-levels-of-automation",
    "relUrl": "/#sae-five-levels-of-automation"
  },"5": {
    "doc": "Introduction",
    "title": "How does it work?",
    "content": "The modern road environment is unpredictable and interpreting it is fundamental. To this end AVs are equipped with RADAR and LIDAR to map the depth of local environment. Camera-arrays provide a finer picture of the near environment and use parallax to judge distance which can be corroborated with range-finding sensors, and ultrasonic sensors for judging the distance to extremely close obstacles such as other cars and curbs. Inertial sensors (IMUs), odometers and GPS can judge the motion, pitch, yaw and roll of the vehicle in space independently. In the event other more precise, but more fragile, sensors be rendered inoperative the inertial sensors can also function as a failsafe to control the vehicle to a safe halt. This data is processed in real time by the OS to create a map of both the static environment, and dynamic objects within the environment. This map, or state, is combined with the vehicles state, and passed to the decision-making stack. The first stage of this stack is route planning, the vehicle generates waypoints to its destination based on the known road layout and any perceived changes. This is then passed to a behavioural layer which “reasons about the environment and generates a motion specification to progress along the selected route.” . Using the motion specification and data about the vehicle’s orientation and local space, the motion layer then plans the vehicle’s manoeuvre as a path vector. Finally, the path vector and the vehicle’s current state is used by the local feedback control layer to generate individual inputs to the vehicle itself. (Paden et al, 2016) . All four of these layers can be implemented using classical computer science solutions, such as A* for route planning, and a Finite State Machine or Markov Decision Processes for behaviour. However Deep Learning techniques such as Convoluted Neural Networks (CNNs) are particularly well suited to some tasks such as image recognition and modelling spatial information. ",
    "url": "/#how-does-it-work",
    "relUrl": "/#how-does-it-work"
  },"6": {
    "doc": "Introduction",
    "title": "Introduction",
    "content": " ",
    "url": "/",
    "relUrl": "/"
  },"7": {
    "doc": "Matt",
    "title": "Matt’s Reflections",
    "content": " ",
    "url": "/reflections/matt/#matts-reflections",
    "relUrl": "/reflections/matt/#matts-reflections"
  },"8": {
    "doc": "Matt",
    "title": "Matt",
    "content": " ",
    "url": "/reflections/matt/",
    "relUrl": "/reflections/matt/"
  },"9": {
    "doc": "Opportunities",
    "title": "Opportunities",
    "content": " ",
    "url": "/opportunities/",
    "relUrl": "/opportunities/"
  },"10": {
    "doc": "Opportunities",
    "title": "Improve road safety",
    "content": "The improvements to road safety represents one of the brightest hopes of self-driving technology. The WHO estimated that in 2018 the number of road fatalities for that year had reached 1.35 million. It has become the leading cause of death for persons aged 5-29, and the 8th leading cause of death for all age groups, outpacing historical killers such as disease and famine. Research into road accidents tends to place human error as a cause more than 90% of the time. This may represent a bias against human judgement. With any failure not attributable to mechanical failure or an unpredictable environment defaulting to ‘blame the driver.’ Despite this, human error is undoubtedly a significant contributor to road accident. Whilst Sweden leads the world in road safety, with Stockholm having the lowest fatality rates among the European capitals, its pioneering ‘Vision Zero’ approach has only managed to reduce its road toll by 66%, not 90%. With tireless mind and superhuman senses, the AI driver seems the perfect candidate to close this gap. As an alternative to irresponsible behaviour such as driving while fatigued, distracted, intoxicated or under the effects of prescription or non-prescription drugs, self-driving cars will likely have the most to give. Resources that are currently invested into driver education and awareness campaigns would then be free to be reinvested into other avenues to improve road safety. Even the model human driver, cautious and attentive, cannot escape the decay in skill that comes with age, and like all skills there are diminishing returns and increasing costs on further instruction to improve human driving ability. Inversely, new advances in AI software and hardware will may see self-driving cars continue to improve generationally, or even over the course of the life of the vehicle via software updates. The first LASER cost as much as a small house , 40 years later the cheapest cost less than a dollar. It is conceivable that history may repeat, and sensors that are prohibitively expensive for autonomous systems now, may in future be cost-effective. ",
    "url": "/opportunities/#improve-road-safety",
    "relUrl": "/opportunities/#improve-road-safety"
  },"11": {
    "doc": "Opportunities",
    "title": "Safety improvements for vehicular design",
    "content": "As the need to design cars around a human driver drops away, vehicular design may change to better accommodate existing or new needs, such as comfort or safety. Much of contemporary vehicle’s surface area is glass. This is a safety necessity for a human driver. With self-driving vehicles comes the need to externalise sensors. Once the human driver is disestablished from the vehicle’s design, glass becomes a safety risk rather than a safety necessity. Whilst still “a dream” as Nilesh Barla writing for neptune.ai puts it, vehicle-to-vehicle networking is very much an avenue that will be explored as networking technologies and algorithms improve in accuracy and efficiency. Sensor fusion already used by cutting-edge militaries like the United States to provide a more complete picture of the battlespace to soldiers. Within civilian transport infrastructure it could be used to enhance an automated vehicle’s decision making and to shore up an individual vehicle’s view of its surrounding if part of its sensor suite becomes incapable of providing the system with useful data in the event of damage, interference, jamming or blinding. ",
    "url": "/opportunities/#safety-improvements-for-vehicular-design",
    "relUrl": "/opportunities/#safety-improvements-for-vehicular-design"
  },"12": {
    "doc": "Opportunities",
    "title": "Protecting the most vulnerable road users",
    "content": "Cyclists and motorcyclists are severely represented in road accidents. ",
    "url": "/opportunities/#protecting-the-most-vulnerable-road-users",
    "relUrl": "/opportunities/#protecting-the-most-vulnerable-road-users"
  },"13": {
    "doc": "References",
    "title": "References",
    "content": "Holstein, T. Dodig-Crnkovic, G., &amp; Pelliccione, P. (2018). Ethical and Social Aspects of Self-Driving Cars. arXiv, 1802(04103), 2-7. https://doi.org/10.48550/arXiv.1802.04103 . Karnouskos, S. (2021). The role of utilitarianism, self-safety, and technology in the acceptance of self-driving cars. Cogn Tech Work, 23, 659–667. https://doi.org/10.1007/s10111-020-00649-6 . Sivak, M., &amp; Schoettle, B. (2015). Road Safety with Self-Driving Vehicles: General Limitations and Road Sharing with Conventional Vehicles. UMTRI, 2015(2), 9. ",
    "url": "/references/",
    "relUrl": "/references/"
  },"14": {
    "doc": "Reflections",
    "title": "Reflections",
    "content": " ",
    "url": "/reflections/",
    "relUrl": "/reflections/"
  },"15": {
    "doc": "Risks & Challenges",
    "title": "Risks and Challenges",
    "content": " ",
    "url": "/risks/#risks-and-challenges",
    "relUrl": "/risks/#risks-and-challenges"
  },"16": {
    "doc": "Risks & Challenges",
    "title": "Deep Learning Models are opaque in their decision-making",
    "content": "Deep learning models, like those used in AI, are inherently opaque. Engineers may understand what the car sensed, and how the car responded, to a situation, but the actual decision-making occurs in a black box. This is in sharp contrast to the state-based and deterministic automated systems we are accustomed to. When these types of systems fail a decision-making process, the failure can be identified, fixed and tested with a high degree of confidence. When a deep learning model fails, the answer is simply ‘more data’. ",
    "url": "/risks/#deep-learning-models-are-opaque-in-their-decision-making",
    "relUrl": "/risks/#deep-learning-models-are-opaque-in-their-decision-making"
  },"17": {
    "doc": "Risks & Challenges",
    "title": "Ethical dilemmas + the trolley problem",
    "content": "Addressing the problem of AI ethics will be critical for public acceptance of self-driving cars, and failure to properly align AI decision-making may have serious long-term consequences for the self-driving industry. The question of ethics is cast into its sharpest relief when introducing vehicle AI to dilemmas: scenarios in which no matter which course the car takes, some harm is inevitable. This represents a new frontier for humanity, never before have we tasked machines with valuing human life. The MIT launched ‘The Moral Machine experiment’ in June 2016 with the goal of starting discussion and providing moral guidance to self-driving vehicle designers. Survey participants were provided with a birds-eye view of an ethical dilemma and tasked with picking a preferred outcome the dilemma. The findings demonstrated a strong preference for sparing human lives over those of pets, sparing more people over fewer, sparing the young, and sparing those lawful and of higher status (e.g. doctor). These preferences however vary significantly by region, for example countries in the ‘Eastern’ region (broadly speaking, every Eurasian country between Iran and Japan) having a preference towards the elderly. The broad array of correlations between distinct cultures suggests that the question of the machine ethics may not have a one-size-fits-all solution, despite much talk of the need for AI to reflect human values. Some argue that the focus on ‘trolley problem’ style dilemmas is misguided altogether. Human drivers are taught to break without swerving in the case of emergency. This procedure is not recommended merely because it is instinctive and simple, but due to the nature of vehicular physics. “Put in its simplest form, the problem is that swerving sufficiently to avoid an object that is within a car’s stopping distance is always a wildly risky manoeuvre compared to straight-line braking.” The self-driving trolley problem can now be seen as an additional choice between a controlled manoeuvre with known risks, and an uncontrolled manoeuvre with unknown risks. (Davnall, 2019) . (Furey, 2020) argues that the focus on ‘trolley problem’ style dilemmas may cause more harm than good. Specifically, that by focusing on accidents that represent edge cases, the adoption of AVs may have been slowed, preventing them from saving lives attributed one of the primary causes of road accidents: human driver error. Furthermore, Furey argues it may place unnecessary moral discomfort on the public: “[The Moral Machine] has caused the public to think they must choose between purchasing an autonomous vehicle that protects their family and one that is moral.” . ",
    "url": "/risks/#ethical-dilemmas--the-trolley-problem",
    "relUrl": "/risks/#ethical-dilemmas--the-trolley-problem"
  },"18": {
    "doc": "Risks & Challenges",
    "title": "Need for new infrastructure",
    "content": " ",
    "url": "/risks/#need-for-new-infrastructure",
    "relUrl": "/risks/#need-for-new-infrastructure"
  },"19": {
    "doc": "Risks & Challenges",
    "title": "Need new legal framework",
    "content": "Currently legal framework is not suitable for handling liability in the event of an accident involving a truly autonomous vehicle. Currently all self-driving cars on the road have a ‘steward’ or ‘safety-driver’ behind the wheel that can take control if things go wrong and is ultimately responsible for the vehicle’s safe passage. This is a temporary ‘band aid’ solution that eventually needs addressing. Whilst it is conceivable that in the future the AI that drive vehicles will be agents, with legal rights and responsibilities, this does not represent the immediate reality of self-driving vehicles. With the user giving up control of the vehicle, they have also given up their responsibility for its safe use (Gurney 2017). This stance is of absolute necessity to the adoption of AVs, no consumer wants to purchase the Car of Damocles. ",
    "url": "/risks/#need-new-legal-framework",
    "relUrl": "/risks/#need-new-legal-framework"
  },"20": {
    "doc": "Risks & Challenges",
    "title": "Public Acceptance",
    "content": "Having the technology of self-driving cars up to a good standard is insufficient by itself, as the public’s trust is equally important. When the technology is quite recent and beyond our control, we are naturally more risk averse. In a study by Schoettle and Sivak on the public opinion of self-driving cars, majority of respondents expressed high levels of concerns about riding in a self-driving car. This is due to the fear/risk of safety issues malfunctioning relating to equipment or system failure. There were also concerns about self-driving cars not performing as well as human drivers. Last year, 378 people were killed on New Zealand’s roads. This is not the number to beat for autonomous vehicle engineers. Polling suggests that the public acceptance of AVs would require this number to be lowered by a factor of 10. This risk aversion poses a risk, as an excessively cautious approach as a result from high-profile accidents could potentially hinder the acceptance and development of self-driving cars. This failure could prevent millions from life-changing injury or even death. ",
    "url": "/risks/#public-acceptance",
    "relUrl": "/risks/#public-acceptance"
  },"21": {
    "doc": "Risks & Challenges",
    "title": "Transition Period",
    "content": "The transitory period when self-driving cars are first unleashed on public roads marks one of the greatest potential risk periods. At this time self-driving cars will be working from relatively small datasets of ‘real world’ scenarios and no amount of public messaging is going to ensure that every ‘Joe Public’ is going to respond to these new cars in a sensible manner. “It takes a long time to turn over the U.S. fleet of light-duty vehicles, with the average vehicular age currently being 11.4 years (IHS, 2014). Therefore, there will likely be at least a several-decade-long period during which conventional and self-driving vehicles would need to interact.” (Sivak et al., 2015) . During this transition period, it is important to acknowledge the risks of the coexistence between self-driving cars and conventional vehicles, as safety may worsen. A quote from Sivak states “Furthermore, in many current situations, interacting drivers of conventional vehicles make eye contact and proceed according to the feedback received from other drivers. Such feedback would be absent in interactions with self-driving vehicles.” This is due to feedback bouncing off drivers on the road to make decisions are being eliminated due to self-driving cars. ",
    "url": "/risks/#transition-period",
    "relUrl": "/risks/#transition-period"
  },"22": {
    "doc": "Risks & Challenges",
    "title": "Risks & Challenges",
    "content": " ",
    "url": "/risks/",
    "relUrl": "/risks/"
  },"23": {
    "doc": "Thomas",
    "title": "Thomas’ Reflections",
    "content": " ",
    "url": "/reflections/thomas/#thomas-reflections",
    "relUrl": "/reflections/thomas/#thomas-reflections"
  },"24": {
    "doc": "Thomas",
    "title": "Thomas",
    "content": " ",
    "url": "/reflections/thomas/",
    "relUrl": "/reflections/thomas/"
  }
}
