---
title: Risks & Challenges
layout: home
permalink: /risks/
nav_order: 3
---

# Risks and Challenges

## Deep Learning Models are opaque in their decision-making

Deep learning models, like those used in AI, are inherently opaque. Engineers may understand what the car sensed, and how the car responded, to a situation, but the actual decision-making occurs in a black box.

This is in sharp contrast to the state-based and deterministic automated systems we are accustomed to. When these types of systems fail a decision-making process, the failure can be identified, fixed and tested with a high degree of confidence. When a deep learning model fails, the answer is simply 'more data’.

## Ethical dilemmas + the trolley problem

Addressing the problem of AI ethics will be critical for public acceptance of self-driving cars, and failure to properly align AI decision-making may have serious long-term consequences for the self-driving industry. The question of ethics is cast into its sharpest relief when introducing vehicle AI to dilemmas: scenarios in which no matter which course the car takes, some harm is inevitable. This represents a new frontier for humanity, never before have we tasked machines with valuing human life.

The MIT launched 'The Moral Machine experiment’ in June 2016 with the goal of starting discussion and providing moral guidance to self-driving vehicle designers. Survey participants were provided with a birds-eye view of an ethical dilemma and tasked with picking a preferred outcome the dilemma. The findings demonstrated a strong preference for sparing human lives over those of pets, sparing more people over fewer, sparing the young, and sparing those lawful and of higher status (e.g. doctor).

These preferences however vary significantly by region, for example countries in the 'Eastern’ region (broadly speaking, every Eurasian country between Iran and Japan) having a preference towards the elderly. The broad array of correlations between distinct cultures suggests that the question of the machine ethics may not have a one-size-fits-all solution, despite much talk of the need for AI to reflect human values.

Some argue that the focus on 'trolley problem’ style dilemmas is misguided altogether. Human drivers are taught to break without swerving in the case of emergency. This procedure is not recommended merely because it is instinctive and simple, but due to the nature of vehicular physics. "Put in its simplest form, the problem is that swerving sufficiently to avoid an object that is within a car’s stopping distance is always a wildly risky manoeuvre compared to straight-line braking.” The self-driving trolley problem can now be seen as an additional choice between a controlled manoeuvre with known risks, and an uncontrolled manoeuvre with unknown risks. (Davnall, 2019)

(Furey, 2020) argues that the focus on 'trolley problem’ style dilemmas may cause more harm than good. Specifically, that by focusing on accidents that represent edge cases, the adoption of AVs may have been slowed, preventing them from saving lives attributed one of the primary causes of road accidents: human driver error. Furthermore, Furey argues it may place unnecessary moral discomfort on the public: "[The Moral Machine] has caused the public to think they must choose between purchasing an autonomous vehicle that protects their family and one that is moral.”

## Need for new infrastructure

## Need new legal framework

Currently legal framework is not suitable for handling liability in the event of an accident involving a truly autonomous vehicle. Currently all self-driving cars on the road have a 'steward’ or 'safety-driver’ behind the wheel that can take control if things go wrong and is ultimately responsible for the vehicle’s safe passage. This is a temporary 'band aid’ solution that eventually needs addressing.

Whilst it is conceivable that in the future the AI that drive vehicles will be agents, with legal rights and responsibilities, this does not represent the immediate reality of self-driving vehicles.
With the user giving up control of the vehicle, they have also given up their responsibility for its safe use (Gurney 2017). This stance is of absolute necessity to the adoption of AVs, no consumer wants to purchase the Car of Damocles.

## Public Acceptance

Having the technology of self-driving cars up to a good standard is insufficient by itself, as the public’s trust is equally important. When the technology is quite recent and beyond our control, we are naturally more risk averse.
In a study by Schoettle and Sivak on the public opinion of self-driving cars, majority of respondents expressed high levels of concerns about riding in a self-driving car. This is due to the fear/risk of safety issues malfunctioning relating to equipment or system failure. There were also concerns about self-driving cars not performing as well as human drivers.
Last year, 378 people were killed on New Zealand’s roads. This is not the number to beat for autonomous vehicle engineers. Polling suggests that the public acceptance of AVs would require this number to be lowered by a factor of 10.
This risk aversion poses a risk, as an excessively cautious approach as a result from high-profile accidents could potentially hinder the acceptance and development of self-driving cars. This failure could prevent millions from life-changing injury or even death.

## Transition Period

The transitory period when self-driving cars are first unleashed on public roads marks one of the greatest potential risk periods. At this time self-driving cars will be working from relatively small datasets of 'real world’ scenarios and no amount of public messaging is going to ensure that every 'Joe Public’ is going to respond to these new cars in a sensible manner.

"It takes a long time to turn over the U.S. fleet of light-duty vehicles, with the average vehicular age currently being 11.4 years (IHS, 2014). Therefore, there will likely be at least a several-decade-long period during which conventional and self-driving vehicles would need to interact.” (Sivak et al., 2015)

During this transition period, it is important to acknowledge the risks of the coexistence between self-driving cars and conventional vehicles, as safety may worsen. A quote from Sivak states "Furthermore, in many current situations, interacting drivers of conventional vehicles make eye contact and proceed according to the feedback received from other drivers. Such feedback would be absent in interactions with self-driving vehicles.” This is due to feedback bouncing off drivers on the road to make decisions are being eliminated due to self-driving cars.
